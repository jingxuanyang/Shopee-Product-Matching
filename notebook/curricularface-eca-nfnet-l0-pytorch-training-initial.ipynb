{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3.8.3 64-bit ('base': conda)","name":"python383jvsc74a57bd00b64f3f517ef2f38123c9b9d844dc7ba7aeffcc4559b7061ceea5f8a66fe5b86"},"language_info":{"name":"python","version":"3.8.3","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":["# Previous kernels \n","\n","**Training**<br>\n","[eca_nfnet_l0 + ArcFace] : https://www.kaggle.com/parthdhameliya77/shopee-pytorch-eca-nfnet-l0-image-training\n","\n","**Inference**<br>\n","\n","ResNext50-32x4d (LB >= 0.72) : https://www.kaggle.com/parthdhameliya77/pytorch-resnext50-32x4d-image-tfidf-inference (Adam+relu activation) <br>\n","EfficientNet B3 (LB >= 0.723) : https://www.kaggle.com/parthdhameliya77/pytorch-efficientnet-b3-image-tfidf-inference (Adam+relu activation) <br>\n","EfficientNet B5 (LB >= 0.729) : https://www.kaggle.com/parthdhameliya77/pytorch-efficientnet-b3-image-tfidf-inference (Adam+relu activation) <br>\n","EfficientNet B5 (LB >= 0.729) : (Ranger+mish activation) <br>\n","\n","# About this kernel \n","\n","In this training kernel, I used **'eca_nfnet_l0'(from timm)** + **CurricularFace** Module. 'eca_nfnet_l0' contains **SiLU()** activation, so I replaced it with **Mish()** activation. Reason to change Mish() activation is beacuse here I am using **Ranger(RAdam + Lookahead)optimizer** and **Mish() + Ranger optimizer** gives a good result (Based on few experiments, I may be wrong). You can try the same strategy to other models too."],"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"markdown","source":["<center><img src=\"https://www.programmersought.com/images/653/8746a02b316eef34dbd8bd83d10ee625.JPEG\"/ width=\"440\" height=\"440\" ></center>"],"metadata":{}},{"cell_type":"markdown","source":["# Imports"],"metadata":{}},{"cell_type":"code","source":["import sys\n","\n","sys.path.append('../input/shopee-competition-utils')\n","sys.path.insert(0,'../input/pytorch-image-models')"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np \n","import pandas as pd \n","\n","import torch \n","from torch import nn \n","from torch.utils.data import Dataset, DataLoader \n","\n","import albumentations\n","from albumentations.pytorch.transforms import ToTensorV2\n","\n","from custom_scheduler import ShopeeScheduler\n","from custom_activation import replace_activations, Mish\n","from custom_optimizer import Ranger\n","\n","import math \n","import cv2\n","import timm \n","import os \n","\n","from sklearn.preprocessing import LabelEncoder\n","from tqdm.notebook import tqdm "],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Config"],"metadata":{}},{"cell_type":"code","source":["class CFG: \n","    \n","    DATA_DIR = '../input/shopee-product-matching/train_images'\n","    TRAIN_CSV = '../input/shopee-product-matching/train.csv'\n","\n","    IMG_SIZE = 512\n","    MEAN = [0.485, 0.456, 0.406]\n","    STD = [0.229, 0.224, 0.225]\n","\n","    EPOCHS = 1 #15\n","    BATCH_SIZE = 8\n","\n","    NUM_WORKERS = 4\n","    DEVICE = 'cuda'\n","\n","    CLASSES = 11014 \n","    SCALE = 30\n","    MARGIN = 0.5\n","\n","    MODEL_NAME = 'eca_nfnet_l0'\n","    FC_DIM = 512\n","    SCHEDULER_PARAMS = {\n","            \"lr_start\": 1e-5,\n","            \"lr_max\": 1e-5 * 32,\n","            \"lr_min\": 1e-6,\n","            \"lr_ramp_ep\": 5,\n","            \"lr_sus_ep\": 0,\n","            \"lr_decay\": 0.8,\n","        }"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Augmentations"],"metadata":{}},{"cell_type":"code","source":["def get_train_transforms():\n","    return albumentations.Compose(\n","        [   \n","            albumentations.Resize(CFG.IMG_SIZE,CFG.IMG_SIZE,always_apply=True),\n","            albumentations.HorizontalFlip(p=0.5),\n","            albumentations.VerticalFlip(p=0.5),\n","            albumentations.Rotate(limit=120, p=0.8),\n","            albumentations.RandomBrightness(limit=(0.09, 0.6), p=0.5),\n","            albumentations.Normalize(mean = CFG.MEAN, std = CFG.STD),\n","            ToTensorV2(p=1.0),\n","        ]\n","    )"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset "],"metadata":{}},{"cell_type":"code","source":["class ShopeeDataset(torch.utils.data.Dataset):\n","\n","    def __init__(self,df, transform = None):\n","        self.df = df \n","        self.root_dir = CFG.DATA_DIR\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.df)\n","\n","    def __getitem__(self,idx):\n","\n","        row = self.df.iloc[idx]\n","\n","        img_path = os.path.join(self.root_dir,row.image)\n","        image = cv2.imread(img_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        label = row.label_group\n","\n","        if self.transform:\n","            augmented = self.transform(image=image)\n","            image = augmented['image']\n","\n","        return {\n","            'image' : image,\n","            'label' : torch.tensor(label).long()\n","        }"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Curricular Face + NFNet-L0"],"metadata":{}},{"cell_type":"markdown","source":["\n","- **Curricular Face** : https://arxiv.org/pdf/2004.00288.pdf"],"metadata":{}},{"cell_type":"markdown","source":["<center><img src=\"https://pbs.twimg.com/media/EVOupMwUcAAaGP7.jpg\"/ width=\"440\" height=\"440\" ></center>"],"metadata":{}},{"cell_type":"code","source":["'''\n","credit : https://github.com/HuangYG123/CurricularFace/blob/8b2f47318117995aa05490c05b455b113489917e/head/metrics.py#L70\n","'''\n","\n","def l2_norm(input, axis = 1):\n","    norm = torch.norm(input, 2, axis, True)\n","    output = torch.div(input, norm)\n","\n","    return output\n","\n","class CurricularFace(nn.Module):\n","    def __init__(self, in_features, out_features, s = 30, m = 0.50):\n","        super(CurricularFace, self).__init__()\n","\n","        print('Using Curricular Face')\n","\n","        self.in_features = in_features\n","        self.out_features = out_features\n","        self.m = m\n","        self.s = s\n","        self.cos_m = math.cos(m)\n","        self.sin_m = math.sin(m)\n","        self.threshold = math.cos(math.pi - m)\n","        self.mm = math.sin(math.pi - m) * m\n","        self.kernel = nn.Parameter(torch.Tensor(in_features, out_features))\n","        self.register_buffer('t', torch.zeros(1))\n","        nn.init.normal_(self.kernel, std=0.01)\n","\n","    def forward(self, embbedings, label):\n","        embbedings = l2_norm(embbedings, axis = 1)\n","        kernel_norm = l2_norm(self.kernel, axis = 0)\n","        cos_theta = torch.mm(embbedings, kernel_norm)\n","        cos_theta = cos_theta.clamp(-1, 1)  # for numerical stability\n","        with torch.no_grad():\n","            origin_cos = cos_theta.clone()\n","        target_logit = cos_theta[torch.arange(0, embbedings.size(0)), label].view(-1, 1)\n","\n","        sin_theta = torch.sqrt(1.0 - torch.pow(target_logit, 2))\n","        cos_theta_m = target_logit * self.cos_m - sin_theta * self.sin_m #cos(target+margin)\n","        mask = cos_theta > cos_theta_m\n","        final_target_logit = torch.where(target_logit > self.threshold, cos_theta_m, target_logit - self.mm)\n","\n","        hard_example = cos_theta[mask]\n","        with torch.no_grad():\n","            self.t = target_logit.mean() * 0.01 + (1 - 0.01) * self.t\n","        cos_theta[mask] = hard_example * (self.t + hard_example)\n","        cos_theta.scatter_(1, label.view(-1, 1).long(), final_target_logit)\n","        output = cos_theta * self.s\n","        return output, nn.CrossEntropyLoss()(output,label)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class ShopeeModel(nn.Module):\n","\n","    def __init__(\n","        self,\n","        n_classes = CFG.CLASSES,\n","        model_name = CFG.MODEL_NAME,\n","        fc_dim = CFG.FC_DIM,\n","        margin = CFG.MARGIN,\n","        scale = CFG.SCALE,\n","        use_fc = True,\n","        pretrained = True):\n","\n","\n","        super(ShopeeModel,self).__init__()\n","        print('Building Model Backbone for {} model'.format(model_name))\n","\n","        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n","\n","        if 'efficientnet' in model_name:\n","            final_in_features = self.backbone.classifier.in_features\n","            self.backbone.classifier = nn.Identity()\n","            self.backbone.global_pool = nn.Identity()\n","        \n","        elif 'nfnet' in model_name:\n","            final_in_features = self.backbone.head.fc.in_features\n","            self.backbone.head.fc = nn.Identity()\n","            self.backbone.head.global_pool = nn.Identity()\n","\n","        self.pooling =  nn.AdaptiveAvgPool2d(1)\n","\n","        self.use_fc = use_fc\n","\n","        if use_fc:\n","            self.dropout = nn.Dropout(p=0.0)\n","            self.fc = nn.Linear(final_in_features, fc_dim)\n","            self.bn = nn.BatchNorm1d(fc_dim)\n","            self._init_params()\n","            final_in_features = fc_dim\n","\n","        self.final = CurricularFace(final_in_features, \n","                                           n_classes, \n","                                           s=scale, \n","                                           m=margin)\n","\n","    def _init_params(self):\n","        nn.init.xavier_normal_(self.fc.weight)\n","        nn.init.constant_(self.fc.bias, 0)\n","        nn.init.constant_(self.bn.weight, 1)\n","        nn.init.constant_(self.bn.bias, 0)\n","\n","    def forward(self, image, label):\n","        feature = self.extract_feat(image)\n","        logits = self.final(feature,label)\n","        return logits\n","\n","    def extract_feat(self, x):\n","        batch_size = x.shape[0]\n","        x = self.backbone(x)\n","        x = self.pooling(x).view(batch_size, -1)\n","\n","        if self.use_fc:\n","            x = self.dropout(x)\n","            x = self.fc(x)\n","            x = self.bn(x)\n","        return x\n"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Engine"],"metadata":{}},{"cell_type":"code","source":["def train_fn(model, data_loader, optimizer, scheduler, i):\n","    model.train()\n","    fin_loss = 0.0\n","    tk = tqdm(data_loader, desc = \"Epoch\" + \" [TRAIN] \" + str(i+1))\n","\n","    for t,data in enumerate(tk):\n","        for k,v in data.items():\n","            data[k] = v.to(CFG.DEVICE)\n","        optimizer.zero_grad()\n","        _, loss = model(**data)\n","        loss.backward()\n","        optimizer.step() \n","        fin_loss += loss.item() \n","\n","        tk.set_postfix({'loss' : '%.6f' %float(fin_loss/(t+1)), 'LR' : optimizer.param_groups[0]['lr']})\n","\n","    scheduler.step()\n","\n","    return fin_loss / len(data_loader)\n","\n","def eval_fn(model, data_loader, i):\n","    model.eval()\n","    fin_loss = 0.0\n","    tk = tqdm(data_loader, desc = \"Epoch\" + \" [VALID] \" + str(i+1))\n","\n","    with torch.no_grad():\n","        for t,data in enumerate(tk):\n","            for k,v in data.items():\n","                data[k] = v.to(CFG.DEVICE)\n","            _, loss = model(**data)\n","            fin_loss += loss.item() \n","\n","            tk.set_postfix({'loss' : '%.6f' %float(fin_loss/(t+1))})\n","        return fin_loss / len(data_loader)"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training "],"metadata":{}},{"cell_type":"code","source":["def run_training():\n","    \n","    df = pd.read_csv(CFG.TRAIN_CSV)\n","\n","    labelencoder= LabelEncoder()\n","    df['label_group'] = labelencoder.fit_transform(df['label_group'])\n","    \n","    trainset = ShopeeDataset(df, transform = get_train_transforms())\n","\n","    trainloader = torch.utils.data.DataLoader(\n","        trainset,\n","        batch_size = CFG.BATCH_SIZE,\n","        pin_memory = True,\n","        num_workers = CFG.NUM_WORKERS,\n","        shuffle = True,\n","        drop_last = True\n","    )\n","\n","    print(df['label_group'].nunique())\n","\n","    model = ShopeeModel(n_classes = df['label_group'].nunique())\n","    model = replace_activations(model, torch.nn.SiLU, Mish())\n","    model.to(CFG.DEVICE)\n","\n","    optimizer = Ranger(model.parameters(), lr = CFG.SCHEDULER_PARAMS['lr_start'])\n","    #optimizer = torch.optim.Adam(model.parameters(), lr = config.SCHEDULER_PARAMS['lr_start'])\n","    scheduler = ShopeeScheduler(optimizer,**CFG.SCHEDULER_PARAMS)\n","\n","    for i in range(CFG.EPOCHS):\n","\n","        avg_loss_train = train_fn(model, trainloader, optimizer, scheduler, i)\n","        torch.save(model.state_dict(),'c_face_eca_nfnet_l0.pt')\n","        \n","run_training()"],"metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}