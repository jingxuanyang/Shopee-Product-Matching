{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd00b64f3f517ef2f38123c9b9d844dc7ba7aeffcc4559b7061ceea5f8a66fe5b86",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../input/shopee-competition-utils')\n",
    "sys.path.insert(0,'../input/pytorch-image-models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Parameter\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "from custom_scheduler import ShopeeScheduler\n",
    "from custom_activation import replace_activations, Mish\n",
    "from custom_optimizer import Ranger\n",
    "\n",
    "import math\n",
    "import cv2\n",
    "import timm\n",
    "import os\n",
    "import random\n",
    "import gc\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CFG: \n",
    "    \n",
    "    DATA_DIR = '../input/shopee-product-matching/train_images'\n",
    "    TRAIN_CSV = '../input/shopee-product-matching/train.csv'\n",
    "\n",
    "    # data augmentation\n",
    "    IMG_SIZE = 512\n",
    "    MEAN = [0.485, 0.456, 0.406]\n",
    "    STD = [0.229, 0.224, 0.225]\n",
    "\n",
    "    SEED = 2021\n",
    "\n",
    "    # data split\n",
    "    N_SPLITS = 5\n",
    "    TEST_FOLD = 0\n",
    "    VALID_FOLD = 1\n",
    "\n",
    "    EPOCHS = 8\n",
    "    BATCH_SIZE = 8\n",
    "\n",
    "    NUM_WORKERS = 4\n",
    "    DEVICE = 'cuda:0'\n",
    "\n",
    "    CLASSES = 6609 \n",
    "    SCALE = 30\n",
    "    MARGINS = [0.5,0.6,0.7,0.8,0.9]\n",
    "    MARGIN = 0.5\n",
    "\n",
    "    BEST_THRESHOLD = 0.19\n",
    "    BEST_THRESHOLD_MIN2 = 0.225\n",
    "\n",
    "    MODEL_NAME = 'resnet50'\n",
    "    MODEL_NAMES = ['resnet50','resnext50_32x4d','densenet121','efficientnet_b3','eca_nfnet_l0']\n",
    "    LOSS_MODULE = 'arc'\n",
    "    LOSS_MODULES = ['arc','curricular']\n",
    "    USE_ARCFACE = True\n",
    "    MODEL_PATH = f'{MODEL_NAME}_{LOSS_MODULE}_face_epoch_8_bs_8_margin_{MARGIN}.pt'\n",
    "    FC_DIM = 512\n",
    "    SCHEDULER_PARAMS = {\n",
    "            \"lr_start\": 1e-5,\n",
    "            \"lr_max\": 1e-5 * 32,\n",
    "            \"lr_min\": 1e-6,\n",
    "            \"lr_ramp_ep\": 5,\n",
    "            \"lr_sus_ep\": 0,\n",
    "            \"lr_decay\": 0.8,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True # set True to be faster\n",
    "\n",
    "seed_everything(CFG.SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_transforms():\n",
    "    return albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(CFG.IMG_SIZE,CFG.IMG_SIZE,always_apply=True),\n",
    "            albumentations.Normalize(mean=CFG.MEAN, std=CFG.STD),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShopeeImageDataset(torch.utils.data.Dataset):\n",
    "    \"\"\"for validating and test\n",
    "    \"\"\"\n",
    "    def __init__(self,df, transform = None):\n",
    "        self.df = df \n",
    "        self.root_dir = CFG.DATA_DIR\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "        row = self.df.iloc[idx]\n",
    "\n",
    "        img_path = os.path.join(self.root_dir,row.image)\n",
    "        image = cv2.imread(img_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = row.label_group\n",
    "\n",
    "        if self.transform:\n",
    "            augmented = self.transform(image=image)\n",
    "            image = augmented['image']     \n",
    "                \n",
    "        return image,torch.tensor(1)"
   ]
  },
  {
   "source": [
    "## ArcMarginProduct"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcMarginProduct(nn.Module):\n",
    "    r\"\"\"Implement of large margin arc distance: :\n",
    "        Args:\n",
    "            in_features: size of each input sample\n",
    "            out_features: size of each output sample\n",
    "            s: norm of input feature\n",
    "            m: margin\n",
    "            cos(theta + m)\n",
    "        \"\"\"\n",
    "    def __init__(self, in_features, out_features, s=30.0, m=0.50, easy_margin=False, ls_eps=0.0):\n",
    "        print('Using Arc Face')\n",
    "        super(ArcMarginProduct, self).__init__()\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.s = s\n",
    "        self.m = m\n",
    "        self.ls_eps = ls_eps  # label smoothing\n",
    "        self.weight = Parameter(torch.FloatTensor(out_features, in_features))\n",
    "        nn.init.xavier_uniform_(self.weight)\n",
    "\n",
    "        self.easy_margin = easy_margin\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.th = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "\n",
    "    def forward(self, input, label):\n",
    "        # --------------------------- cos(theta) & phi(theta) ---------------------------\n",
    "        cosine = F.linear(F.normalize(input), F.normalize(self.weight))\n",
    "        sine = torch.sqrt(1.0 - torch.pow(cosine, 2))\n",
    "        phi = cosine * self.cos_m - sine * self.sin_m\n",
    "        if self.easy_margin:\n",
    "            phi = torch.where(cosine > 0, phi, cosine)\n",
    "        else:\n",
    "            phi = torch.where(cosine > self.th, phi, cosine - self.mm)\n",
    "        # --------------------------- convert label to one-hot ---------------------------\n",
    "        # one_hot = torch.zeros(cosine.size(), requires_grad=True, device='cuda')\n",
    "        one_hot = torch.zeros(cosine.size(), device=CFG.DEVICE)\n",
    "        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n",
    "        if self.ls_eps > 0:\n",
    "            one_hot = (1 - self.ls_eps) * one_hot + self.ls_eps / self.out_features\n",
    "        # -------------torch.where(out_i = {x_i if condition_i else y_i) -------------\n",
    "        output = (one_hot * phi) + ((1.0 - one_hot) * cosine)\n",
    "        output *= self.s\n",
    "\n",
    "        return output, nn.CrossEntropyLoss()(output,label)"
   ]
  },
  {
   "source": [
    "## CurricularFace"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "credit : https://github.com/HuangYG123/CurricularFace/blob/8b2f47318117995aa05490c05b455b113489917e/head/metrics.py#L70\n",
    "'''\n",
    "\n",
    "def l2_norm(input, axis = 1):\n",
    "    norm = torch.norm(input, 2, axis, True)\n",
    "    output = torch.div(input, norm)\n",
    "\n",
    "    return output\n",
    "\n",
    "class CurricularFace(nn.Module):\n",
    "    def __init__(self, in_features, out_features, s = 30, m = 0.50):\n",
    "        super(CurricularFace, self).__init__()\n",
    "\n",
    "        print('Using Curricular Face')\n",
    "\n",
    "        self.in_features = in_features\n",
    "        self.out_features = out_features\n",
    "        self.m = m\n",
    "        self.s = s\n",
    "        self.cos_m = math.cos(m)\n",
    "        self.sin_m = math.sin(m)\n",
    "        self.threshold = math.cos(math.pi - m)\n",
    "        self.mm = math.sin(math.pi - m) * m\n",
    "        self.kernel = nn.Parameter(torch.Tensor(in_features, out_features))\n",
    "        self.register_buffer('t', torch.zeros(1))\n",
    "        nn.init.normal_(self.kernel, std=0.01)\n",
    "\n",
    "    def forward(self, embbedings, label):\n",
    "        embbedings = l2_norm(embbedings, axis = 1)\n",
    "        kernel_norm = l2_norm(self.kernel, axis = 0)\n",
    "        cos_theta = torch.mm(embbedings, kernel_norm)\n",
    "        cos_theta = cos_theta.clamp(-1, 1)  # for numerical stability\n",
    "        with torch.no_grad():\n",
    "            origin_cos = cos_theta.clone()\n",
    "        target_logit = cos_theta[torch.arange(0, embbedings.size(0)), label].view(-1, 1)\n",
    "\n",
    "        sin_theta = torch.sqrt(1.0 - torch.pow(target_logit, 2))\n",
    "        cos_theta_m = target_logit * self.cos_m - sin_theta * self.sin_m #cos(target+margin)\n",
    "        mask = cos_theta > cos_theta_m\n",
    "        final_target_logit = torch.where(target_logit > self.threshold, cos_theta_m, target_logit - self.mm)\n",
    "\n",
    "        hard_example = cos_theta[mask]\n",
    "        with torch.no_grad():\n",
    "            self.t = target_logit.mean() * 0.01 + (1 - 0.01) * self.t\n",
    "        cos_theta[mask] = hard_example * (self.t + hard_example)\n",
    "        cos_theta.scatter_(1, label.view(-1, 1).long(), final_target_logit)\n",
    "        output = cos_theta * self.s\n",
    "        return output, nn.CrossEntropyLoss()(output,label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShopeeModel(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_classes = CFG.CLASSES,\n",
    "        model_name = CFG.MODEL_NAME,\n",
    "        fc_dim = CFG.FC_DIM,\n",
    "        margin = CFG.MARGIN,\n",
    "        scale = CFG.SCALE,\n",
    "        use_fc = True,\n",
    "        pretrained = True,\n",
    "        use_arcface = CFG.USE_ARCFACE):\n",
    "\n",
    "        super(ShopeeModel,self).__init__()\n",
    "        print(f'Building Model Backbone for {model_name} model, margin = {margin}')\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if 'efficientnet' in model_name:\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "        \n",
    "        elif 'resnet' in model_name:\n",
    "            final_in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif 'resnext' in model_name:\n",
    "            final_in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif 'densenet' in model_name:\n",
    "            final_in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Identity()\n",
    "            self.backbone.global_pool = nn.Identity()\n",
    "\n",
    "        elif 'nfnet' in model_name:\n",
    "            final_in_features = self.backbone.head.fc.in_features\n",
    "            self.backbone.head.fc = nn.Identity()\n",
    "            self.backbone.head.global_pool = nn.Identity()\n",
    "\n",
    "        self.pooling =  nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        self.use_fc = use_fc\n",
    "\n",
    "        if use_fc:\n",
    "            self.dropout = nn.Dropout(p=0.0)\n",
    "            self.fc = nn.Linear(final_in_features, fc_dim)\n",
    "            self.bn = nn.BatchNorm1d(fc_dim)\n",
    "            self._init_params()\n",
    "            final_in_features = fc_dim\n",
    "\n",
    "        if use_arcface:\n",
    "            self.final = ArcMarginProduct(final_in_features, \n",
    "                                                n_classes, \n",
    "                                                s=scale, \n",
    "                                                m=margin)\n",
    "        else:\n",
    "            self.final = CurricularFace(final_in_features, \n",
    "                                                n_classes, \n",
    "                                                s=scale, \n",
    "                                                m=margin)\n",
    "\n",
    "    def _init_params(self):\n",
    "        nn.init.xavier_normal_(self.fc.weight)\n",
    "        nn.init.constant_(self.fc.bias, 0)\n",
    "        nn.init.constant_(self.bn.weight, 1)\n",
    "        nn.init.constant_(self.bn.bias, 0)\n",
    "\n",
    "    def forward(self, image, label):\n",
    "        feature = self.extract_feat(image)\n",
    "        logits = self.final(feature,label)\n",
    "        return logits\n",
    "\n",
    "    def extract_feat(self, x):\n",
    "        batch_size = x.shape[0]\n",
    "        x = self.backbone(x)\n",
    "        x = self.pooling(x).view(batch_size, -1)\n",
    "\n",
    "        if self.use_fc:\n",
    "            x = self.dropout(x)\n",
    "            x = self.fc(x)\n",
    "            x = self.bn(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset():\n",
    "    df = pd.read_csv(CFG.TRAIN_CSV)\n",
    "    df['matches'] = df.label_group.map(df.groupby('label_group').posting_id.agg('unique').to_dict())\n",
    "    df['matches'] = df['matches'].apply(lambda x: ' '.join(x))\n",
    "\n",
    "    gkf = GroupKFold(n_splits=CFG.N_SPLITS)\n",
    "    df['fold'] = -1\n",
    "    for i, (train_idx, valid_idx) in enumerate(gkf.split(X=df, groups=df['label_group'])):\n",
    "        df.loc[valid_idx, 'fold'] = i\n",
    "\n",
    "    labelencoder= LabelEncoder()\n",
    "    df['label_group'] = labelencoder.fit_transform(df['label_group'])\n",
    "\n",
    "    train_df = df[df['fold']!=CFG.TEST_FOLD].reset_index(drop=True)\n",
    "    train_df = train_df[train_df['fold']!=CFG.VALID_FOLD].reset_index(drop=True)\n",
    "    valid_df = df[df['fold']==CFG.VALID_FOLD].reset_index(drop=True)\n",
    "    test_df = df[df['fold']==CFG.TEST_FOLD].reset_index(drop=True)\n",
    "\n",
    "    train_df['label_group'] = labelencoder.fit_transform(train_df['label_group'])\n",
    "\n",
    "    return train_df, valid_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    precision = intersection / len_y_pred\n",
    "    return precision\n",
    "\n",
    "def recall_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    recall = intersection / len_y_true\n",
    "    return recall\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    y_true = y_true.apply(lambda x: set(x.split()))\n",
    "    y_pred = y_pred.apply(lambda x: set(x.split()))\n",
    "    intersection = np.array([len(x[0] & x[1]) for x in zip(y_true, y_pred)])\n",
    "    len_y_pred = y_pred.apply(lambda x: len(x)).values\n",
    "    len_y_true = y_true.apply(lambda x: len(x)).values\n",
    "    f1 = 2 * intersection / (len_y_pred + len_y_true)\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_embeddings(df, model):\n",
    "\n",
    "    image_dataset = ShopeeImageDataset(df,transform=get_test_transforms())\n",
    "    image_loader = torch.utils.data.DataLoader(\n",
    "        image_dataset,\n",
    "        batch_size=CFG.BATCH_SIZE,\n",
    "        pin_memory=True,\n",
    "        num_workers = CFG.NUM_WORKERS,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    embeds = []\n",
    "    with torch.no_grad():\n",
    "        for img,label in tqdm(image_loader): \n",
    "            img = img.to(CFG.DEVICE)\n",
    "            label = label.to(CFG.DEVICE)\n",
    "            feat,_ = model(img,label)\n",
    "            image_embeddings = feat.detach().cpu().numpy()\n",
    "            embeds.append(image_embeddings)\n",
    "    \n",
    "    del model\n",
    "    image_embeddings = np.concatenate(embeds)\n",
    "    print(f'Our image embeddings shape is {image_embeddings.shape}')\n",
    "    del embeds\n",
    "    gc.collect()\n",
    "    return image_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_neighbors(df, embeddings, threshold = 0.2, min2 = False):\n",
    "\n",
    "    nbrs = NearestNeighbors(n_neighbors = 50, metric = 'cosine')\n",
    "    nbrs.fit(embeddings)\n",
    "    distances, indices = nbrs.kneighbors(embeddings)\n",
    "\n",
    "    predictions = []\n",
    "    for k in range(embeddings.shape[0]):\n",
    "        if min2:\n",
    "            idx = np.where(distances[k,] < CFG.BEST_THRESHOLD)[0]\n",
    "            ids = indices[k,idx]\n",
    "            if len(ids) <= 1 and distances[k,1] < threshold:\n",
    "                ids = np.append(ids,indices[k,1])\n",
    "        else:\n",
    "            idx = np.where(distances[k,] < threshold)[0]\n",
    "            ids = indices[k,idx]\n",
    "        posting_ids = ' '.join(df['posting_id'].iloc[ids].values)\n",
    "        predictions.append(posting_ids)\n",
    "        \n",
    "    df['pred_matches'] = predictions\n",
    "    df['f1'] = f1_score(df['matches'], df['pred_matches'])\n",
    "    df['recall'] = recall_score(df['matches'], df['pred_matches'])\n",
    "    df['precision'] = precision_score(df['matches'], df['pred_matches'])\n",
    "    \n",
    "    del nbrs, distances, indices\n",
    "    gc.collect()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_best_threshold(valid_df,model):\n",
    "    search_space = np.arange(10, 50, 1)\n",
    "    valid_embeddings = get_image_embeddings(valid_df, model)\n",
    "\n",
    "    print(\"Searching best threshold...\")\n",
    "    best_f1_valid = 0.\n",
    "    best_threshold = 0.\n",
    "    for i in search_space:\n",
    "        threshold = i / 100\n",
    "        valid_df = get_image_neighbors(valid_df, valid_embeddings, threshold=threshold)\n",
    "        valid_f1 = valid_df.f1.mean()\n",
    "        valid_recall = valid_df.recall.mean()\n",
    "        valid_precision = valid_df.precision.mean()\n",
    "        print(f\"threshold = {threshold} -> f1 score = {valid_f1}, recall = {valid_recall}, precision = {valid_precision}\")\n",
    "        if (valid_f1 > best_f1_valid):\n",
    "            best_f1_valid = valid_f1\n",
    "            best_threshold = threshold\n",
    "\n",
    "    print(\"Best threshold =\", best_threshold)\n",
    "    print(\"Best f1 score =\", best_f1_valid)\n",
    "    CFG.BEST_THRESHOLD = best_threshold\n",
    "\n",
    "    # phase 2 search\n",
    "    print(\"Searching best min2 threshold...\")\n",
    "    search_space = np.arange(CFG.BEST_THRESHOLD * 100, CFG.BEST_THRESHOLD * 100 + 20, 0.5)\n",
    "\n",
    "    best_f1_valid = 0.\n",
    "    best_threshold = 0.\n",
    "\n",
    "    for i in search_space:\n",
    "        threshold = i / 100\n",
    "        valid_df = get_image_neighbors(valid_df, valid_embeddings, threshold=threshold,min2=True)\n",
    "\n",
    "        valid_f1 = valid_df.f1.mean()\n",
    "        valid_recall = valid_df.recall.mean()\n",
    "        valid_precision = valid_df.precision.mean()\n",
    "\n",
    "        print(f\"min2 threshold = {threshold} -> f1 score = {valid_f1}, recall = {valid_recall}, precision = {valid_precision}\")\n",
    "\n",
    "        if (valid_f1 > best_f1_valid):\n",
    "            best_f1_valid = valid_f1\n",
    "            best_threshold = threshold\n",
    "\n",
    "    print(\"Best min2 threshold =\", best_threshold)\n",
    "    print(\"Best f1 score after min2 =\", best_f1_valid)\n",
    "    CFG.BEST_THRESHOLD_MIN2 = best_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_embeddings():\n",
    "    \"\"\"Save valid and test image embeddings.\n",
    "    \"\"\"\n",
    "    train_df, valid_df, test_df = read_dataset()\n",
    "    PATH_PREFIX = '../input/image-model-trained/'\n",
    "    for i in range(len(CFG.LOSS_MODULES)):\n",
    "        CFG.LOSS_MODULE = CFG.LOSS_MODULES[i]\n",
    "        if 'arc' in CFG.LOSS_MODULE:\n",
    "            CFG.USE_ARCFACE = True\n",
    "        else:\n",
    "            CFG.USE_ARCFACE = False\n",
    "        for j in range(len(CFG.MODEL_NAMES)):\n",
    "            CFG.MODEL_NAME = CFG.MODEL_NAMES[j]\n",
    "            for k in range(len(CFG.MARGINS)):\n",
    "                CFG.MARGIN = CFG.MARGINS[k]\n",
    "                model = ShopeeModel(model_name = CFG.MODEL_NAME,\n",
    "                                    margin = CFG.MARGIN,\n",
    "                                    use_arcface = CFG.USE_ARCFACE)\n",
    "                model.eval()\n",
    "                model = replace_activations(model, torch.nn.SiLU, Mish())\n",
    "                CFG.MODEL_PATH = f'{CFG.MODEL_NAME}_{CFG.LOSS_MODULE}_face_epoch_8_bs_8_margin_{CFG.MARGIN}.pt'\n",
    "                MODEL_PATH = PATH_PREFIX + CFG.MODEL_PATH\n",
    "                model.load_state_dict(torch.load(MODEL_PATH))\n",
    "                model = model.to(CFG.DEVICE)\n",
    "\n",
    "                valid_embeddings = get_image_embeddings(valid_df, model)\n",
    "                VALID_EMB_PATH = '../input/image-embeddings/' + CFG.MODEL_PATH[:-3] + '_valid_embed.csv'\n",
    "                np.savetxt(VALID_EMB_PATH, valid_embeddings, delimiter=',')\n",
    "\n",
    "                TEST_EMB_PATH = '../input/image-embeddings/' + CFG.MODEL_PATH[:-3] + '_test_embed.csv'\n",
    "                test_embeddings = get_image_embeddings(test_df, model)\n",
    "                np.savetxt(TEST_EMB_PATH, test_embeddings, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Building Model Backbone for resnet50 model, margin = 0.5\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4852493250f49a9927f14653e5f55dc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4e2fc2299d0f4ea79feac2f8971d1fb6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for resnet50 model, margin = 0.6\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dba70abf95be4e689b3d6506b46bca47"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fef3083582c34f2a9cf5f718176d3462"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for resnet50 model, margin = 0.7\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "280f6a710fb04d73ac92deeea10ce003"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "4b8d1d6e843f410cb152668788a839a1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for resnet50 model, margin = 0.8\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bea3bb15e5c645e595d37df9fc126e0c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b1733f328154b8dbcd000123c09b555"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for resnet50 model, margin = 0.9\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b55cdd38a0c0485684803c3853cb3539"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "143c45a6d33f481e8d93b2845b11b2ff"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for resnext50_32x4d model, margin = 0.5\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "321bff11d85449f2badf8c45d16e8331"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6ed6630344c4cf4add47c7f8f200286"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for resnext50_32x4d model, margin = 0.6\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "11a9fec11b1643808990947d46d72361"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "aeb2a062fc734d698c30aedca732ff48"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for resnext50_32x4d model, margin = 0.7\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cb01c30059404ddaa2bf4969cdafe2cc"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1675099b0a24b36ac499e010a7946ac"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for resnext50_32x4d model, margin = 0.8\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "95bb364c74fb4e91a535c3bab386decd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9804fe1a5b3043fd949cf9f74e47b1d1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for resnext50_32x4d model, margin = 0.9\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2255d58ead334cc9b28272d0647cb0ce"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b8ce725eed284d69a56ee19c35b094f4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for densenet121 model, margin = 0.5\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19724de8a5aa48b09e976f3e659c0ea6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "61f3a429e69c4ab9846fc46667908fa6"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for densenet121 model, margin = 0.6\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6bd90ba74c7c49f2a18fab556171022d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0542660a7ca74785955ca6c4cb2a57b5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for densenet121 model, margin = 0.7\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "048038b969a7405f9833290b33efc336"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e6e6104136e84ebfa4a1f8808f6bb48b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for densenet121 model, margin = 0.8\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8e95b1de51f4c7d9d620bfeb705010f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "475d98d9d1024ccf84c1846fe8070404"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for densenet121 model, margin = 0.9\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79fa7eff8562496498634e605e6f0e46"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cac2ed4cc7e04ceab0eb74b091666fc3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for efficientnet_b3 model, margin = 0.5\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "755bc6c681b9433d8a937c5f84f6e4de"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06415441973649ca94b9ce47f281e036"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for efficientnet_b3 model, margin = 0.6\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7412c471a3fe45b4a1a4c11771826b03"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a6d689c8ff2d4bad8302845cc6c0c545"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for efficientnet_b3 model, margin = 0.7\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "da15ad7382e9441aaabae1c91ca8f1f3"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3f2d143f6fc046739f5edf711bd7dd26"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for efficientnet_b3 model, margin = 0.8\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "79cf772268664ccc8b631aa085160827"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5b3360f3ce84063959f7192f2ffb909"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for efficientnet_b3 model, margin = 0.9\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b5b148fdcfb4373b67235e010c4340b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5da9beccf65d4e9c86c36930ae5c452d"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for eca_nfnet_l0 model, margin = 0.5\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e7d4bab4722c4af6aa50bddb8c7b4f4f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c5b9993b75b94a59a4d5b53394c816f5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for eca_nfnet_l0 model, margin = 0.6\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "231d43b4e9224ab3921e9942346b8a2c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7fe8af36b2b944d79e12e20f44d8713c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for eca_nfnet_l0 model, margin = 0.7\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3ce731f6ed024254ab2398ab813efe8f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "05043a37648a41d89efa9ccf955432bb"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for eca_nfnet_l0 model, margin = 0.8\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b43c03d3c504c379e1a3484891f01a2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d7978320303b48c1ab721b26f02d1e65"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for eca_nfnet_l0 model, margin = 0.9\n",
      "Using Arc Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6b3aad4c312749cabe60410765b3ef20"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "58f0a89841ea4917b0ff13bd20fc22da"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for resnet50 model, margin = 0.5\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2cf39bc26a2840cdbb6e74f3f8affd0b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0ea62790cfdb4c8e86bd1f9e4ee99bc9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for resnet50 model, margin = 0.6\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1df8c8b054d94ea8865808fe2e9a623a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c7c47993c31647de9268010886175090"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for resnet50 model, margin = 0.7\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e29163a446a34979a2305cd3f9bd1d84"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03b42589b4ad49ffa711cb7eb60344fa"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for resnet50 model, margin = 0.8\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2f0a4517927429c90bf2b0e65989fc4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "672a84bf1dcb438fa799889190e41d0a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for resnet50 model, margin = 0.9\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6850bd13e498455393fc5a01461b659f"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5808290414ed49efb4e62b840c7d9e35"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for resnext50_32x4d model, margin = 0.5\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d17db8d6d2a74023be63a6709232b75c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8cabc25803544eed81453d95574313ee"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for resnext50_32x4d model, margin = 0.6\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8580b4baac0b4436a546d8ebbb78aa82"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "03e9af4a2d1b4268a22f7969775a4547"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for resnext50_32x4d model, margin = 0.7\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b98bddc9faac429fa11a302d74a1db79"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c141ac19db3e416b8840ccbdc89df87a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for resnext50_32x4d model, margin = 0.8\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5a1ee854a91345c3832bc8204f5686cd"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8a7d43faa0284c509876045ddf5d7ff1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for resnext50_32x4d model, margin = 0.9\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dbde2e5188d84c078a26bac786cbf4ac"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec7c7d484bfe44329029f332d42001d4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for densenet121 model, margin = 0.5\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "590d3ec9a9454d6fbee7b2bb8f6a0034"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3b46d40b83274c909cc1ce657ad68b32"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for densenet121 model, margin = 0.6\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ca4b9b7c1985494aaa8e0c01264c2cef"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92179e3cf47c4224982621f5e107f75a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for densenet121 model, margin = 0.7\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "71fb1d0cf3964c098b1624d087b45aab"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7376ad2f3c9147e4b5408708730daf9c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for densenet121 model, margin = 0.8\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9b82a8cc26ef42dc827909605c6ae568"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "06ae7d9c48574ada9b7516364c33ec1a"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for densenet121 model, margin = 0.9\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2e377c7e3d0744b4af7e68d84bdaf0ef"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "317c1410211c413dbed6852b7569d9e5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for efficientnet_b3 model, margin = 0.5\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d58c5e06bf3f4dec8653a5fbe3fe1860"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "730958193791495d8fa84b538c3aa8d2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for efficientnet_b3 model, margin = 0.6\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "fd9a6ad26ce04413af366b655f623849"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "38aea6ed15354ef4874837b5767990ab"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for efficientnet_b3 model, margin = 0.7\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9563fe7a33c6479b8cddbd4c10ad76e9"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8b5d87c5a34e46099fa2e3278d28d96e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for efficientnet_b3 model, margin = 0.8\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "815be9ceea4c4453a5615e92b4aa0f5c"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "01005e5d82f6496a836ff764bb25f23e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for efficientnet_b3 model, margin = 0.9\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c562e6ee09264262b7cd51ddc2529123"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "23e91e2245e54a35b3ca117f9d935ed5"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for eca_nfnet_l0 model, margin = 0.5\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b9d3c040a41c4359acca162159ec3391"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "8250d7765bb14bdcb2e1c722fb2f98a1"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for eca_nfnet_l0 model, margin = 0.6\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "642a637078184ae1a8904bec63443b24"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "90c5cc94e623473293c6146a7a1550c4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for eca_nfnet_l0 model, margin = 0.7\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2507276c8b2b47bb9fead911e06b0f06"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3cabe9b69c4f41bfb164606683b3bd1e"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for eca_nfnet_l0 model, margin = 0.8\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a4a0937e48a84a0585b867da091f6cd2"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5da02a54a05749659697ba2c15b320e4"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "Our image embeddings shape is (6851, 6609)\n",
      "Building Model Backbone for eca_nfnet_l0 model, margin = 0.9\n",
      "Using Curricular Face\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6694c0afb85c4426ae37a481d2961381"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6849, 6609)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=0.0, max=857.0), HTML(value='')))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "db7d3e1153754f7b9ceebc0a00a16a0b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\nOur image embeddings shape is (6851, 6609)\n"
     ]
    }
   ],
   "source": [
    "save_embeddings()"
   ]
  },
  {
   "source": [
    "## Run test\n",
    "\n",
    "Parameters:\n",
    "+ `CFG.MARGIN = [0.5,0.6,0.7,0.8,0.9]`\n",
    "+ `CFG.MODEL_NAME = ['resnet50','resnext50_32x4d','densenet121','efficientnet_b3','eca_nfnet_l0']`\n",
    "+ `CFG.LOSS_MODULE = ['arc','curricular']`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## save and load embeddings\n",
    "\n",
    "+ `np.savetxt('tf_efficientnet_b5_ns.csv', image_embeddings1, delimiter=',')`\n",
    "+ `image_embeddings4 = np.loadtxt(CFG.image_embeddings4_path, delimiter=',')`\n",
    "+ `image_embeddings4_path = '../input/image-embeddings/efficientnet_b3.csv'`"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}